{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import tweepy\n",
    "\n",
    "# ADD OTHER PACKAGES WE WILL NEED\n",
    "import requests as re\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['TWITTER_API_KEY']\n",
    "api_secret = os.environ['TWITTER_API_KEY_SECRET']\n",
    "access_token = os.environ['TWITTER_ACCESS_TOKEN']\n",
    "access_token_secret = os.environ['TWITTER_ACCESS_TOKEN_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up auth request\n",
    "\n",
    "auth_url = \"https://api.twitter.com/oauth2/token?grant_type=client_credentials\"\n",
    "\n",
    "auth_data = {\n",
    "    'username' : api_key,\n",
    "    'password' : api_secret\n",
    "}\n",
    "\n",
    "auth_auth = (api_key, api_secret)\n",
    "\n",
    "auth_params = {\n",
    "    'grant_type': \"client_credentials\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_type': 'bearer',\n",
       " 'access_token': 'AAAAAAAAAAAAAAAAAAAAALGrdAEAAAAAGqBpaO1LxiIGQ441DMvVo38qwgw%3De0ZtyRzQvrAJkwDrmyJVHRvhwbJXsKUVyMM4riZDkYsI8Dnbb0'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the response\n",
    "\n",
    "auth_response = re.post(auth_url, data=auth_data, auth=auth_auth)\n",
    "auth_response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAAAAAAAAAAAAAAAAAAAALGrdAEAAAAAGqBpaO1LxiIGQ441DMvVo38qwgw%3De0ZtyRzQvrAJkwDrmyJVHRvhwbJXsKUVyMM4riZDkYsI8Dnbb0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## assign the response\n",
    "token_type = auth_response.json()['token_type']\n",
    "access_token = auth_response.json()['access_token']\n",
    "access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[StreamRule(value='#datascience lang:en', tag=None, id='1534531538771140610')], includes={}, errors=[], meta={'sent': '2022-06-08T13:43:25.204Z', 'summary': {'created': 1, 'not_created': 0, 'valid': 1, 'invalid': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## set-up streaming client\n",
    "\n",
    "streaming_client = tweepy.StreamingClient(access_token)\n",
    "streaming_client.add_rules(tweepy.StreamRule(\"#datascience lang:en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[StreamRule(value='#datascience lang:en', tag=None, id='1534531538771140610')], includes={}, errors=[], meta={'sent': '2022-06-08T13:43:30.993Z', 'result_count': 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look at rules\n",
    "\n",
    "streaming_client.get_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=None, includes={}, errors=[], meta={'sent': '2022-06-08T13:43:13.841Z', 'summary': {'deleted': 1, 'not_deleted': 0}})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## delete rules\n",
    "\n",
    "streaming_client.delete_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Set-Up Printer\n",
    "\n",
    "# class StatusPrinter(tweepy.StreamingClient):\n",
    "\n",
    "#     def on_tweet(self, tweet):\n",
    "#         print(tweet)\n",
    "\n",
    "# printer = StatusPrinter(access_token)\n",
    "# #printer.filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatusListener(tweepy.StreamingClient):\n",
    "    def on_tweet(self, tweet):\n",
    "        with open(\"output.txt\", 'a') as f:\n",
    "            f.write(json.dumps(tweet.text))\n",
    "            f.write('\\n')\n",
    "            print(tweet)\n",
    "\n",
    "main = StatusListener(access_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @ponderdata: üî•üî•New release for Modin 0.15!\n",
      "\n",
      "Read more about what's packed in this new release here: https://t.co/w4mWyYjso5\n",
      "\n",
      "#opensource‚Ä¶\n",
      "RT @foldercase_com: #FAIRdata starts in your own research group and collaborations.\n",
      "\n",
      "Utilization (and exchange) of standards, data inventor‚Ä¶\n",
      "RT @GraceyEssays: For quality assignment help\n",
      "#Essaypay\n",
      "Exams\n",
      "Homework\n",
      "Bio\n",
      "Chemistry\n",
      "Math\n",
      "Eng\n",
      "Ecology\n",
      "Anatomy\n",
      "#MachineLearning  #DataScienc‚Ä¶\n",
      "RT @MHiesboeck: üí∏What are the Key Benefits of #Blockchain #Technology in Trade #Finance‚ùì\n",
      "\n",
      "#Fintech #Tech #AI #NLP #DataScience #BigData #An‚Ä¶\n",
      "RT @data_schools: Optional units allow flexibility for how the NPA Data Science can be taught - in computing science, maths, across multipl‚Ä¶\n",
      "RT @GraceyEssays: For quality assignment help\n",
      "#Essaypay\n",
      "Exams\n",
      "Homework\n",
      "Bio\n",
      "Chemistry\n",
      "Math\n",
      "Eng\n",
      "Ecology\n",
      "Anatomy\n",
      "#MachineLearning  #DataScienc‚Ä¶\n",
      "RT @rasangarocks: Learning Python, 5th Edition\n",
      "\n",
      "Link - https://t.co/u9oLicU6WW\n",
      "\n",
      "#Python #100DaysOfCode #CodeNewbies #WomenWhoCode #DEVCommu‚Ä¶\n",
      "RT @GraceyEssays: For quality assignment help\n",
      "#Essaypay\n",
      "Exams\n",
      "Homework\n",
      "Bio\n",
      "Chemistry\n",
      "Math\n",
      "Eng\n",
      "Ecology\n",
      "Anatomy\n",
      "#MachineLearning  #DataScienc‚Ä¶\n",
      "RT @Mayassignment: Hire us to do your\n",
      "Exams\n",
      "Nursing\n",
      "Essays\n",
      "History\n",
      "Excel\n",
      "Ecology\n",
      "Literature\n",
      "Law\n",
      "Algebra\n",
      "\n",
      "We will   help  on timely delivery‚Ä¶\n",
      "RT @Blockcircleteam: Blockcircle's own @BaselIsmail shared his industry insights, blockchain data &amp; analytics trends, token valuation model‚Ä¶\n",
      "RT @MustafaRaziq1: Started learning data science from @DataCamp  and got my 1st certificate from the course\n",
      "\n",
      "#DataScience #data #Python #le‚Ä¶\n",
      "RT @DataScienceDojo: üí°Here is a list of 42 projects in Python that you should try out!\n",
      "Source: @RavitJain\n",
      "\n",
      "#Python #Projects #DataScience h‚Ä¶\n",
      "RT @njoyflyfishing: 7 Day Covid Deaths per 1K Population by County For VT   2022-06-03:  Latest Covid Insights by Our Analytics Team using‚Ä¶\n",
      "RT @chamindux: NMAP FULL CHEAT SHEET‚ú®\n",
      "#bugbounty #PentestingBest #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI‚Ä¶\n",
      "RT @poetmail07: Keenon Delivery Robot. \n",
      "(This will be in the issue of The AI Times link https://t.co/emxfzTNAuT\n",
      ")\n",
      "\n",
      "https://t.co/Nj1N0I6IsB‚Ä¶\n",
      "@patilindrajeets Which markdown book do you recommend ?\n",
      "mini-framework for model training and deployment https://t.co/NJ1olZdZXK #deeplearning #machinelearning #ml #ai #neuralnetworks #datascience #TensorFlow\n",
      "@Khulood_Almani Awesome üëå\n",
      "We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming #CodeNewbie\n",
      "#reactjs #bugbounty #DataScience #gamedev\n",
      "#BigData #Analytics #NeuralNetworks #Cloud\n",
      "#OpenSource #Artificial\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @AndrewinContact: How Organizations Use #Data and #Analytics\n",
      "\n",
      "Info via @CatherineAdenle shows #datascience uses in #business &amp; #life. #M‚Ä¶\n",
      "RT @SophiaM29781439: Buy Trustpilot Reviews\n",
      "https://t.co/WJmw36Uw3S\n",
      "#MachineLearning #DataScience #Python #AI #100DaysOfCode #IoT #flutter‚Ä¶\n",
      "RT @programmerjoke9: He demands an apology.#100Daysofcode #javascript #programming #dev #linux #java #programming #CodeNewbie #python #reac‚Ä¶\n",
      "Critical Shift to Data in #Finance Industry = #DataDriven approaches that institutions are taking to meet industry challenges and to innovate: https://t.co/IXKr7kGdvX by @datasocietyco\n",
      "‚Äî‚Äî‚Äî\n",
      "#Fintech #BigData #PredictiveAnalytics #AI #ML #DataScience #FraudDetection #RiskAssessment https://t.co/vPcUtGOyRl\n",
      "RT @rasangarocks: Introduction to Algorithms, fourth edition\n",
      "\n",
      "Link - https://t.co/yrCBzvSSt9\n",
      "\n",
      "#Algorithms #Maths #100DaysOfCode #CodeNewbie‚Ä¶\n",
      "RT @BaselIsmail: I spoke at the @LoopCapital markets conference recently about Web3 / Metaverse / DeFi / CeFi / Mining and Yield Bearing As‚Ä¶\n",
      "#ds #dataanalytic #python #datascience #ml #data #datamining #machinelearning \n",
      "https://t.co/dVCKLqQu1K \n",
      "Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking\n",
      "A-State R User Group Hope to Make a Comeback with Physical Events This Summer  {https://t.co/zlKtNlWh9D} #rstats #DataScience\n",
      "RT @BaselIsmail: I look forward to speaking at the Loop Capital - Crypto, DeFi, and Blockchain for Equity Investors conference tomorrow; th‚Ä¶\n",
      "Which models are interpretable? https://t.co/OgnvBgQBza #analytics #datascience, #bigdata, #datascience, #datascience #ds, #machinelearning\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @AndrewinContact: How Organizations Use #Data and #Analytics\n",
      "\n",
      "Info via @CatherineAdenle shows #datascience uses in #business &amp; #life. #M‚Ä¶\n",
      "@SuhelMemon4 https://t.co/ghabiSe8u1 domain is for sale\n",
      "\n",
      "#blockchain #web3 #NFTs #Metaverse #Cryptos #AI #Digital #TechForGood #cryptocurrency #fintech #Finserv #javascript #coding #innovation #DataScience #Business #Flutter #python #womenintech #Marketing #nft #dao #defi #xyz #fin #seo\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @AdhiSquarePants: Python 3.11 Performance Benchmarks Are Looking Fantastic\n",
      "\n",
      "https://t.co/uUCopgICmB\n",
      "\n",
      "#Python #DataScientist #BigData #An‚Ä¶\n",
      "RT @KirkDBorne: Critical Shift to Data in #Finance Industry = #DataDriven approaches that institutions are taking to meet industry challeng‚Ä¶\n",
      "RT @beerdotbeer: @SuhelMemon4 https://t.co/ghabiSe8u1 domain is for sale\n",
      "\n",
      "#blockchain #web3 #NFTs #Metaverse #Cryptos #AI #Digital #TechFor‚Ä¶\n",
      "RT @programmerjoke9: He demands an apology.#100Daysofcode #javascript #programming #dev #linux #java #programming #CodeNewbie #python #reac‚Ä¶\n",
      "@HakeemJGreen @ImNickHuber Great job! How did you like it?\n",
      "RT @KirkDBorne: Critical Shift to Data in #Finance Industry = #DataDriven approaches that institutions are taking to meet industry challeng‚Ä¶\n",
      "RT @Sheraj99: #Python projects idea that you can try #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #RStat‚Ä¶\n",
      "RT @DataScienceDojo: üí°Here is a list of 42 projects in Python that you should try out!\n",
      "Source: @RavitJain\n",
      "\n",
      "#Python #Projects #DataScience h‚Ä¶\n",
      "RT @Sheraj99: #Python projects idea that you can try #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #RStat‚Ä¶\n",
      "RT @GraceyEssays: For quality assignment help\n",
      "#Essaypay\n",
      "Exams\n",
      "Homework\n",
      "Bio\n",
      "Chemistry\n",
      "Math\n",
      "Eng\n",
      "Ecology\n",
      "Anatomy\n",
      "#MachineLearning  #DataScienc‚Ä¶\n",
      "A library built upon #PyTorch for building embeddings on discrete event sequences using self-supervision https://t.co/t1hXimVAMQ #deeplearning #machinelearning #ml #ai #neuralnetworks #datascience\n",
      "RT @GraceyEssays: For quality assignment help\n",
      "#Essaypay\n",
      "Exams\n",
      "Homework\n",
      "Bio\n",
      "Chemistry\n",
      "Math\n",
      "Eng\n",
      "Ecology\n",
      "Anatomy\n",
      "#MachineLearning  #DataScienc‚Ä¶\n",
      "RT @poetmail07: Google's Robot Butler. \n",
      "(This will be in the issue of The AI Times link https://t.co/emxfzTNAuT\n",
      ")\n",
      "\n",
      "https://t.co/DtLB1Qpb0O‚Ä¶\n",
      "RT @GraceyEssays: For quality assignment help\n",
      "#Essaypay\n",
      "Exams\n",
      "Homework\n",
      "Bio\n",
      "Chemistry\n",
      "Math\n",
      "Eng\n",
      "Ecology\n",
      "Anatomy\n",
      "#MachineLearning  #DataScienc‚Ä¶\n",
      "MamasMatter2 Ô£ø That White Noise Gets Loud#100DaysOfCode #CodeNewbie #WomenWhoCode #Programming #DataScience #Academic‚Ä¶\n",
      "RT @KenCarmen5: MamasMatter2 Ô£ø That White Noise Gets Loud#100DaysOfCode #CodeNewbie #WomenWhoCode #Programming #DataScience #Academic‚Ä¶\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @SocialNetworkSG: Machine Learning with PyTorch\n",
      "#BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #NLProc #Python #RStats‚Ä¶\n",
      "RT @pvergadia: Okay so...here is how you can pick your #AI ML path on @googlecloud \n",
      "\n",
      "https://t.co/jyuikRiPMm\n",
      "\n",
      "#MachineLearning #DataScience\n",
      "RT @stratorob: #Citi sees a $13 trn opportunity in #Metaverse. Does it have the potential?\n",
      "\n",
      "https://t.co/74z9QdM1vY\n",
      "\n",
      "#Technology #NFTCommun‚Ä¶\n",
      "RT @stratorob: #Citi sees a $13 trn opportunity in #Metaverse. Does it have the potential?\n",
      "\n",
      "https://t.co/74z9QdM1vY\n",
      "\n",
      "#Technology #NFTCommun‚Ä¶\n",
      "@cropsiafoods https://t.co/ghabiSe8u1 domain is for sale\n",
      "\n",
      "#blockchain #web3 #NFTs #Metaverse #Cryptos #AI #Digital #TechForGood #cryptocurrency #fintech #Finserv #javascript #coding #innovation #DataScience #Business  #python #womenintech #Marketing #nft #dao #defi #xyz #fin #SEOKJIN\n",
      "RT @RealBenjizo: Python Question;\n",
      "\n",
      "This Python question is from the book  '50 Days of Python '\n",
      "\n",
      "Try it out:\n",
      "\n",
      "#Python #DataScience #TensorFl‚Ä¶\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @beerdotbeer: @cropsiafoods https://t.co/ghabiSe8u1 domain is for sale\n",
      "\n",
      "#blockchain #web3 #NFTs #Metaverse #Cryptos #AI #Digital #TechFo‚Ä¶\n",
      "RT @KirkDBorne: Build intelligent systems as a #MachineLearning Engineer with this comprehensive resource guide: https://t.co/waRkYIuJE7\n",
      "‚Äî‚Äî‚Ä¶\n",
      "RT @beerdotbeer: @cropsiafoods https://t.co/ghabiSe8u1 domain is for sale\n",
      "\n",
      "#blockchain #web3 #NFTs #Metaverse #Cryptos #AI #Digital #TechFo‚Ä¶\n",
      "https://t.co/ghabiSe8u1 domain is for sale\n",
      "\n",
      "#blockchain #web3 #NFTs #Metaverse #Cryptos #AI #Digital #TechForGood #cryptocurrency #fintech #Finserv #javascript #coding #innovation #DataScience #Business  #python #womenintech #Marketing #nft #dao #defi #xyz #fin #SEOKJIN\n",
      "RT @beerdotbeer: https://t.co/ghabiSe8u1 domain is for sale\n",
      "\n",
      "#blockchain #web3 #NFTs #Metaverse #Cryptos #AI #Digital #TechForGood #cryptoc‚Ä¶\n",
      "Here's a preview blog of an ODSC Europe 2022 session on using AI to power trading in finance. #DataScience #Finance https://t.co/KJtCldtRpi\n",
      "RT @KirkDBorne: Infographic from @zakiul33 \n",
      "\n",
      "#Python Libraries and Frameworks\n",
      "‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
      "#MachineLearning #Jupyter #AI #DeepLearning #DataScien‚Ä¶\n",
      "RT @poetmail07: Jasper AI Artificial Intelligence Writer. See some of its features.  (This will be in the issue of The AI Times link https:‚Ä¶\n",
      "RT @KirkDBorne: Critical Shift to Data in #Finance Industry = #DataDriven approaches that institutions are taking to meet industry challeng‚Ä¶\n",
      "RT @KirkDBorne: Build intelligent systems as a #MachineLearning Engineer with this comprehensive resource guide: https://t.co/waRkYIuJE7\n",
      "‚Äî‚Äî‚Ä¶\n",
      "üìäStudy Data Science across June and July 2022. Start date 20th June. ‚¨áÔ∏è #DataScience #DDI https://t.co/RfQSStOQtN\n",
      "RT @KirkDBorne: Critical Shift to Data in #Finance Industry = #DataDriven approaches that institutions are taking to meet industry challeng‚Ä¶\n",
      "RT Learn to differentiate these data roles https://t.co/09Gydr3fAF #dataengineering #dataanalysis #datascience #artificialintelligence https://t.co/l2Eu3jfC4P\n",
      "Thanks for sharing https://t.co/FrDiymwbEp\n",
      "@HACKER_TechS @DevRetweetBot Greatüëèüëèüëè\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "#ml #jupyter #datamodeling #ds #python #datascience #machinelearning #examples  \n",
      " \n",
      "Data Science with Jupyter: Master Data Science skills with easy-to-follow Python examples \n",
      "https://t.co/25c5ioExVZ\n",
      "RT @gp_pulipaka: Top Data Science Books To Transform from Novice to Intermediate. #BigData #Analytics #DataScience #IoT #IIoT #Python #RSta‚Ä¶\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @configuroweb: No. 2362 programming meme #programmingjoke #code #coding #javascript #python #datascience #programming #programmer #joke‚Ä¶\n",
      "RT @HACKER_TechS: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode‚Ä¶\n",
      "RT @AITSNewsletter: Top #digitaltransformation books for your #business\n",
      "\n",
      "https://t.co/WJzQBbQdOE\n",
      "\n",
      "#ArtificialIntelligence #MachineLearning‚Ä¶\n",
      "Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofcodechallenge #100DaysOfCode #SQL https://t.co/KUPEDD8pdG\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "RT @foldercase_com: #FAIRdata starts in your own research group and collaborations.\n",
      "\n",
      "Utilization (and exchange) of standards, data inventor‚Ä¶\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "RT @KirkDBorne: The Most Important Fundamentals of #PyTorch to Know for #DeepLearning: https://t.co/qzkHtpJqB1\n",
      "‚ûï\n",
      "Code repository for the ar‚Ä¶\n",
      "RT @KirkDBorne: Best Online Resources to Learn Data Analysis in 2022 (Courses, Books, Videos, etc) ‚Äî compiled by @tut_ml \n",
      "‚Äî‚Äî‚Äî‚Äî\n",
      "#BigData #Da‚Ä¶\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "#100daysofcode #datascience #programming #python #python3 #introduction #beginner \n",
      " \n",
      "https://t.co/luWpdJkhyV\n",
      " \n",
      "Python Basics: A Practical Introduction to Python 3\n",
      "RT @Sheraj99: Best of #Linux Networking #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Te‚Ä¶\n",
      "@corpus_news keep Tweeting :)\n",
      "RT @JonyMah78: Check out my Gig on Fiverr: I will do 3 modern creative minimalist logo design https://t.co/R915tWEb6j \n",
      "#logo #design #Mufc‚Ä¶\n",
      "RT @corpus_news: #100daysofcode #datascience #programming #python #python3 #introduction #beginner \n",
      " \n",
      "https://t.co/luWpdJkhyV\n",
      " \n",
      "Python Basi‚Ä¶\n",
      "RT @RealBenjizo: Python Question;\n",
      "\n",
      "This Python question is from the book  '50 Days of Python '\n",
      "\n",
      "Try it out:\n",
      "\n",
      "#Python #DataScience #TensorFl‚Ä¶\n",
      "RT @stratorob: #Citi sees a $13 trn opportunity in #Metaverse. Does it have the potential?\n",
      "\n",
      "https://t.co/74z9QdM1vY\n",
      "\n",
      "#Technology #NFTCommun‚Ä¶\n",
      "RT @towards_AI: Check out the best #free #datasets for #machinelearning and #datascience ‚Üí https://t.co/9kBSJzMBRI via @Towards_AI\n",
      "RT @Eli_Krumova: ‚ö°Ô∏èSimple #MachineLearning Workflow\n",
      "https://t.co/Psrum8hOtF\n",
      "By Ramin Rastin\n",
      "\n",
      "v/@mikeflache\n",
      "#ML #AI #DataScience #Analytics‚Ä¶\n",
      "RT @Eli_Krumova: ‚ö°Ô∏èSimple #MachineLearning Workflow\n",
      "https://t.co/Psrum8hOtF\n",
      "By Ramin Rastin\n",
      "\n",
      "v/@mikeflache\n",
      "#ML #AI #DataScience #Analytics‚Ä¶\n",
      "RT @Khulood_Almani: üí•What are theüîüSoft #Skills Needed to Drive #DigitalTransformation‚ùì\n",
      "\n",
      "#Leaders #futureofwork #job #Tech #innovation #Data‚Ä¶\n",
      "I audibly gasped when I saw this paper and then said to myself, \"tell me you were a kid data nerd without telling me you were a kid data nerd.\" \n",
      "\n",
      "#DataScience #datafam #ds4a #DataScientist #probability https://t.co/ZhHByJS7P3\n",
      "Comment curiously\n",
      "\n",
      "#margarita #movement #datascience #work #nft\n",
      "Should I say ‚Äùthere is no difference‚Äù or ‚Äùthe difference is not significant‚Äù?  {https://t.co/cr9cDbsEHR} #rstats #DataScience\n",
      "RT @40dollarbutton: Comment curiously\n",
      "\n",
      "#margarita #movement #datascience #work #nft\n",
      "RT @KirkDBorne: Learn about the new #Python Data #Analytics book by @wesmckinn and about #ApacheArrow here: https://t.co/1ZFlGCsgCM\n",
      "‚Äî‚Äî‚Äî‚Äî\n",
      "#a‚Ä¶\n",
      "RT @Khulood_Almani: What are the9‚É£Pillars of Industry 4.0?\n",
      "\n",
      "v @CircuitDigest\n",
      "#Industry40 #IoT #DataScience #BigData #Analytics #digital #Te‚Ä¶\n",
      "RT @JobPreference: NEED a #JOB?\n",
      "Sign up now https://t.co/o7lVlsCHXv\n",
      "FREE. NO MIDDLEMAN\n",
      "#ArtificialIntelligence #MachineLearning #Python #Da‚Ä¶\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "RT @gp_pulipaka: Distributed Computing! #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Python #RStats #TensorFl‚Ä¶\n",
      "RT @Sheraj99: A Cheat-Sheet for all the Data Structures in #Python. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #RStat‚Ä¶\n",
      "RT @softfree7: AnyMP4 Blu-ray Player FREE License\n",
      "\n",
      "#Telegram:https://t.co/wq0U7Hcjyo\n",
      "\n",
      "#DataScience #tech #innovation #digital #cloud #AI #M‚Ä¶\n",
      "RT @softfree7: AnyMP4 Blu-ray Player FREE License\n",
      "\n",
      "#Telegram:https://t.co/wq0U7Hcjyo\n",
      "\n",
      "#DataScience #tech #innovation #digital #cloud #AI #M‚Ä¶\n",
      "RT @zakiul33: GIT Command Cheat Sheet \n",
      "#MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @JobPreference: NEED a #JOB?\n",
      "Sign up now https://t.co/o7lVlsCHXv\n",
      "FREE. NO MIDDLEMAN\n",
      "#ArtificialIntelligence #MachineLearning #Python #Da‚Ä¶\n",
      "RT @curveslive: mega-absolutely-gorgeous-babes-love-licking-pussy-premium-hd-video\n",
      "https://t.co/2UQvQ93slz\n",
      "#bigdata #DEVCommunity #teChnOlO‚Ä¶\n",
      "Game-changing speedup of #DataAnalytics and #DataWrangling with #ApacheParquet (column-oriented data file format for efficient storage &amp; retrieval): https://t.co/HymvxIlGV9 @rstudio\n",
      "‚Äî‚Äî‚Äî‚Äî\n",
      "#IoT #IIoT #IoTPL #IoTCL #BigData #Analytics #DataScience #AI #MachineLearning #100DaysOfCode https://t.co/DhNbt4BD5H\n",
      "RT @jyanstat: The 4th UConn Sports Analytics Symposium on Oct. 8, 2022: https://t.co/EhVXHeRpri. Register now for the SMT data challenge to‚Ä¶\n",
      "RT @KirkDBorne: Game-changing speedup of #DataAnalytics and #DataWrangling with #ApacheParquet (column-oriented data file format for effici‚Ä¶\n",
      "RT @zakiul33: GIT Command Cheat Sheet \n",
      "#MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @zakiul33: GIT Command Cheat Sheet \n",
      "#MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @DataScienceDojo: üí°Here is a list of 42 projects in Python that you should try out!\n",
      "Source: @RavitJain\n",
      "\n",
      "#Python #Projects #DataScience h‚Ä¶\n",
      "RT @Veracitiz: #infographic: Here are the 100 days of the #DataScience Challenge! Via @ingliguori\n",
      "\n",
      "#datascience #machinelearning #python #a‚Ä¶\n",
      "RT @programmerjoke9: Saved me a ton of times#100Daysofcode #javascript #programming #dev #linux #java #programming #CodeNewbie #python #rea‚Ä¶\n",
      "RT @IainLJBrown: Creating artificial intelligence that acts more human by 'knowing that it knows' - Science Daily\n",
      "\n",
      "Read more here: https://‚Ä¶\n",
      "RT @programmerjoke9: He demands an apology.#100Daysofcode #javascript #programming #dev #linux #java #programming #CodeNewbie #python #reac‚Ä¶\n",
      "Learn to differentiate these data roles https://t.co/cNnywHtY1M #dataengineering #dataanalysis #datascience https://t.co/PueYcYm6Op\n",
      "RT @IainLJBrown: Creating artificial intelligence that acts more human by 'knowing that it knows' - Science Daily\n",
      "\n",
      "Read more here: https://‚Ä¶\n",
      "RT @MedEngineAgency: 1/3üîπWhy choose the Nordic Region for research and trials? MedEngine will take part in Future Clinical Trials conferenc‚Ä¶\n",
      "RT @SophiaM29781439: Buy Trustpilot Reviews\n",
      "https://t.co/WJmw36Uw3S\n",
      "#MachineLearning #DataScience #Python #AI #100DaysOfCode #IoT #flutter‚Ä¶\n",
      "RT @MMominl: #Development #CSS #HTML5 #PHP #NodeJs #WordPress #JavaScript  #javascript30 \n",
      "#BigData #Analytics #DataScience #AI #MachineLear‚Ä¶\n",
      "@SachinP55204445 do you need views a website?\n",
      "Hope you are well..\n",
      "I am a front-end web developer.\n",
      "\n",
      "I can create all kind of website you like.\n",
      "\n",
      "If you need any website:\n",
      "https://t.co/Nwso0XsBJS\n",
      "RT @mariya06025697: Web3 Simply Explained  \n",
      "\n",
      "#21SparksAcademy #MachineLearning #DataScience  #Cybersecurity #BigData #Analytics #Python  #T‚Ä¶\n",
      "RT @foldercase_com: #FAIRdata starts in your own research group and collaborations.\n",
      "\n",
      "Utilization (and exchange) of standards, data inventor‚Ä¶\n",
      "Day 8 of #66daysofdata with #KNIME‚úÖ\n",
      "\n",
      "Today was the day to brush up on statisticsüìà\n",
      "\n",
      "Is mean and average ùëöùëíùëéùëõ the same?\n",
      "https://t.co/Tpr3qhL39x\n",
      "\n",
      "What is descriptive statistics?\n",
      "https://t.co/PuMS9ehqGj\n",
      "https://t.co/I6DONRBa6V\n",
      "\n",
      "#datascience #data #statistics #opensource\n",
      "Cool interview w/ @BDataScientist. Good pt re: how #datascience is becoming intrinsically part of many professions.\n",
      "‚ÄúWhether you‚Äôre a medical doctor or physicist, #datascience will continue to become more of a part of your job.‚Äù \n",
      "via @FortuneMagazine\n",
      "https://t.co/993XQ1AZxF\n",
      "RT @zakiul33: GIT Command Cheat Sheet \n",
      "#MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @colleges_data: üìäStudy Data Science across June and July 2022. Start date 20th June. ‚¨áÔ∏è #DataScience #DDI\n",
      "RT @_SerayArslan: Day 8 of #66daysofdata with #KNIME‚úÖ\n",
      "\n",
      "Today was the day to brush up on statisticsüìà\n",
      "\n",
      "Is mean and average ùëöùëíùëéùëõ the same?\n",
      "htt‚Ä¶\n",
      "RT @labordeolivier: 10 Stats to show How #Analytics Boost #Business!\n",
      "#Data #DataScience #AI #Statistics\n",
      "\n",
      "@sebbourguignon @enilev @Khulood_A‚Ä¶\n",
      "RT @stratorob: #Citi sees a $13 trn opportunity in #Metaverse. Does it have the potential?\n",
      "\n",
      "https://t.co/74z9QdM1vY\n",
      "\n",
      "#Technology #NFTCommun‚Ä¶\n",
      "#ml #statistics #artificialintelligence #ds #datamodeling #ai #machinelearning #python #datascience  \n",
      "\n",
      "https://t.co/z0zscSh0fw\n",
      "Becoming a Data Head: How to Think, Speak and Understand Data Science, Statistics and Machine Learning\n",
      "So excited to see everyone! https://t.co/35ImI1AqDX\n",
      "RT @chamindux: Python Debugging Cheat Sheet\n",
      "\n",
      " #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RSta‚Ä¶\n",
      "RT @Sheraj99: Best of #Linux Networking #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Te‚Ä¶\n",
      "RT @dscottdegeest: I audibly gasped when I saw this paper and then said to myself, \"tell me you were a kid data nerd without telling me you‚Ä¶\n",
      "Demystifying the use of the Parquet file format for #TimeSeries: https://t.co/rsgAn5mX1r by @SenXHQ HT @warp10io \n",
      "‚Äî‚Äî‚Äî‚Äî\n",
      "#IoT #IIoT #IoTPL #IoTCL #BigData #Analytics #DataScience #AI #MachineLearning #PredictiveAnalytics #Forecasting #EdgeComputing #StreamAnalytics #ApacheParquet https://t.co/SH08frQOgw\n",
      "RT @Sheraj99: Best of #Linux Networking #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Te‚Ä¶\n",
      "How to \"Quantile\"?\n",
      "\n",
      "https://t.co/GyUtwUHc64\n",
      "\n",
      "#datascience #data #statistics #opensource\n",
      "RT @_SerayArslan: How to \"Quantile\"?\n",
      "\n",
      "https://t.co/GyUtwUHc64\n",
      "\n",
      "#datascience #data #statistics #opensource\n",
      "RT @Sheraj99: Best of #Linux Networking #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Te‚Ä¶\n",
      "RT @rohanpaul_ai: #openai  #Codex beautifully solving one after another #leetcode Medium Difficulty questions in second\n",
      "\n",
      "#Python #DataScien‚Ä¶\n",
      "RT @DataScienceDojo: üí°Here is a list of 42 projects in Python that you should try out!\n",
      "Source: @RavitJain\n",
      "\n",
      "#Python #Projects #DataScience h‚Ä¶\n",
      "The Critical Shift to Data in the Finance Industry  {https://t.co/GpBI4GCd8K} #rstats #DataScience\n",
      "RT @DataScienceDojo: üí°Here is a list of 42 projects in Python that you should try out!\n",
      "Source: @RavitJain\n",
      "\n",
      "#Python #Projects #DataScience h‚Ä¶\n",
      "RT @Rbloggers: The Critical Shift to Data in the Finance Industry  {https://t.co/GpBI4GCd8K} #rstats #DataScience\n",
      "RT @DataScienceDojo: üí°Here is a list of 42 projects in Python that you should try out!\n",
      "Source: @RavitJain\n",
      "\n",
      "#Python #Projects #DataScience h‚Ä¶\n",
      "RT @milos_agathon: My new maps show staggering differences in traffic death rate between men and women across Europe, according to Eurostat‚Ä¶\n",
      "RT @ingliguori: The Ultimate Guide to Learning About Artificial Intelligence\n",
      "Via @ingliguori \n",
      "https://t.co/HhxLMi6dyv #BigData #Analytics #‚Ä¶\n",
      "RT @xEP_Network: Here is our full MLB Statistical Report for Player Props! All data made by our Algorithms! üî•\n",
      "\n",
      "If a player is not playing t‚Ä¶\n",
      "RT @JobPreference: NEED a #JOB?\n",
      "Sign up now https://t.co/o7lVlsCHXv\n",
      "FREE. NO MIDDLEMAN\n",
      "#ArtificialIntelligence #MachineLearning #Python #Da‚Ä¶\n",
      "RT @KirkDBorne: Critical Shift to Data in #Finance Industry = #DataDriven approaches that institutions are taking to meet industry challeng‚Ä¶\n",
      "RT @Fabriziobustama: Using #AI #scientists Hear ‚ÄúWhat Can‚Äôt Be Heard‚Äù.\n",
      "#ArtificialIntelligence #DataScience\n",
      "#Bigdata #Computervision #IoT\n",
      "C‚Ä¶\n",
      "We all have come so far.\n",
      "#DBMS #DSA #DataScience \n",
      "#oops #oop #language #uiux #uidesign #Trending @riti2409 \n",
      "@PiyushRaj714 @Ashwani17135621 @ADITYAK37929458 https://t.co/gC5fWhtM6t\n",
      "RT @jyanstat: The 4th UConn Sports Analytics Symposium on Oct. 8, 2022: https://t.co/EhVXHeRpri. Register now for the SMT data challenge to‚Ä¶\n",
      "RT @GraceyEssays: We do \n",
      "Statistics\n",
      "PSYCHOLOGY\n",
      "Sociology\n",
      "Immunology\n",
      "Anatomy\n",
      "PHYSIOLOGY\n",
      "Chemistry\n",
      "Physics\n",
      "English\n",
      "Astrology\n",
      "Math\n",
      "Genetics\n",
      "Dm‚Ä¶\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "RT @Khulood_Almani: üßë‚Äç‚öñÔ∏èHigh-tech #Legislation Through Self-regulation\n",
      "\n",
      "https://t.co/fWhOzRk3F1\n",
      "\n",
      "#Tech #law #innovation #DataScience #BigDa‚Ä¶\n",
      "RT @TechTalkHQ_: An illustration with key #AI and #ML components\n",
      "\n",
      "#DigitalTransformation  #MachineLearning #Data #BigData #cybersecurity #1‚Ä¶\n",
      "HACKER TECHs helps in recovering lost social media accounts and solutions #DataScience #tech #innovation #digital\n",
      "#cloud #Al #MachineLearning #loT #Web3\n",
      "#blockchain #100DaysOfCode #TensorFlow #serverless\n",
      "#computing #reactis #startup #VPN #MONEY\n",
      "#FreeNFT #free #onlyfans #usa\n",
      "RT @HACKER_TechS: HACKER TECHs helps in recovering lost social media accounts and solutions #DataScience #tech #innovation #digital\n",
      "#cloud‚Ä¶\n",
      "@HACKER_TechS Amazingüíì We have a hugh network of onlyfans Would you like to take Promo from our page ‚ù§Ô∏è‚ù§Ô∏è\n",
      "Send your Pictures for PROMOTION DM üíå  @fanslypromort üíØ‚úÖ (171k)sub.\n",
      "RT @DataScienceDojo: üí°Here is a list of 42 projects in Python that you should try out!\n",
      "Source: @RavitJain\n",
      "\n",
      "#Python #Projects #DataScience h‚Ä¶\n",
      "RT @HACKER_TechS: HACKER TECHs helps in recovering lost social media accounts and solutions #DataScience #tech #innovation #digital\n",
      "#cloud‚Ä¶\n",
      "RT @softfree7: AnyMP4 Blu-ray Player FREE License\n",
      "\n",
      "#Telegram:https://t.co/wq0U7Hcjyo\n",
      "\n",
      "#DataScience #tech #innovation #digital #cloud #AI #M‚Ä¶\n",
      "@HACKER_TechS Are you interested in new subscriber üíì Send me your Pictures  for ·ë≠·ñáO·ó∞OTIO·ëé DMüåü @fanslypromort üíñ (171k)sub.\n",
      "RT @foldercase_com: #FAIRdata starts in your own research group and collaborations.\n",
      "\n",
      "Utilization (and exchange) of standards, data inventor‚Ä¶\n",
      "RT @Khulood_Almani: ü™üThis glass is electrified to become opaque at the flick of a switch\n",
      "\n",
      "#innovation #TechForGood #technology #coding #100‚Ä¶\n",
      "RT @mytrashcode: No. 2403 programming meme #programmingjoke #code #coding #javascript #python #datascience #programming #programmer #joke #‚Ä¶\n",
      "RT @itsjustliz_YT: Day 156 of #365DaysOfCode \n",
      "\n",
      "Learning PostGreSQL and I feel extra cool! üêç\n",
      "\n",
      "#womenwhocode #DataScience #Python #100daysofc‚Ä¶\n",
      "Build a Career in Data Science\n",
      "\n",
      "#datascience #ds #job #ml #career #machinelearning #datamodeling  \n",
      " \n",
      "https://t.co/cq0A8SObmX\n",
      "The latest The Python Daily! https://t.co/okrrzmYCBZ #python #datascience\n",
      "RT @softfree7: AnyMP4 Blu-ray Player FREE License\n",
      "\n",
      "#Telegram:https://t.co/wq0U7Hcjyo\n",
      "\n",
      "#DataScience #tech #innovation #digital #cloud #AI #M‚Ä¶\n",
      "Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #TensorFlow #JavaScript #ReactJS #CloudComputing #Serverless #DataScientist #Linux #Programming #Coding #100DaysofCode #NodeJS #golang #NLP #GitHub #IoT #MLOps #DL https://t.co/G7GUQdm6EN\n",
      "RT @talibali786: Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Tens‚Ä¶\n",
      "RT @talibali786: Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Tens‚Ä¶\n",
      "A-State R User Group Hope to Make a Comeback with Physical Events This Summer via #rbloggers #rstats #datascience https://t.co/8i73epYdd4\n",
      "RT @talibali786: Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Tens‚Ä¶\n",
      "RT @talibali786: Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Tens‚Ä¶\n",
      "RT @Khulood_Almani: üí•‚õìÔ∏è#BlockChain for #VirtualReality‚û°Ô∏è12 Practical Use Cases\n",
      "\n",
      "#Fintech #VR #NFT #web3 #Metaverse #Tech #AI #ML #DataScien‚Ä¶\n",
      "RT @Sheraj99: A Cheat-Sheet for all the Data Structures in #Python. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #RStat‚Ä¶\n",
      "Best Marketing Plan PowerPoint Presentation Template \n",
      "https://t.co/vYwlIOzjqS\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup #digitalarts #Android #ios #AndroidDev #iosdev #Marketing #SEO #DataScience #AI #5G #charts #MarketingDigital #Sales #Powerpoint #presentation #Infographic https://t.co/D49iHBkn6h\n",
      "RT @GraceyEssays: .Dm @GraceyEssays  \n",
      "Best results\n",
      " GUARANTEED\n",
      "Final exam\n",
      "Biology\n",
      "Essays\n",
      "Chemistry\n",
      "English\n",
      "Ecology\n",
      "Psychology\n",
      "Accounting\n",
      "Ma‚Ä¶\n",
      "RT @Khulood_Almani: üßë‚Äç‚öñÔ∏èHigh-tech #Legislation Through Self-regulation\n",
      "\n",
      "https://t.co/fWhOzRk3F1\n",
      "\n",
      "#Tech #law #innovation #DataScience #BigDa‚Ä¶\n",
      "The Reviews Daily is out! https://t.co/rvpdj7iTVi Stories via @stressedmum01 @darleneowen1234 @gamingthingsSCR #100daysofcode #datascience\n",
      "RT @patilindrajeets: The current state of my library of R programming books! üòªüìö\n",
      "\n",
      "#rstats #programming #datascience https://t.co/7A6q1eDXNW\n",
      "RT @talibali786: Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Tens‚Ä¶\n",
      "RT @talibali786: Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Tens‚Ä¶\n",
      "RT @ISGLOBALorg: The 2nd edition of the International Summer School in #GlobalHealth is coming in September!\n",
      "\n",
      "Learn more about:\n",
      "\n",
      "ü©∫Health Im‚Ä¶\n",
      "RT @sonu_monika: AFib History is the quiet beginning of huge #Apple #health revolution. https://t.co/PrL5xEHsjv #MachineLearning #DataScien‚Ä¶\n",
      "RT @OhayoOkasan: The Reviews Daily is out! https://t.co/rvpdj7iTVi Stories via @stressedmum01 @darleneowen1234 @gamingthingsSCR #100daysofc‚Ä¶\n",
      "@HaroldSinnott @mvollmer1 @Khulood_Almani @chboursin Check out @AceCloudHosting\n",
      "RT @jyanstat: The 4th UConn Sports Analytics Symposium on Oct. 8, 2022: https://t.co/EhVXHeRpri. Register now for the SMT data challenge to‚Ä¶\n",
      "Best Marketing Plan PowerPoint Presentation Template \n",
      "https://t.co/vYwlIOzjqS\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup #digitalarts #Android #ios #AndroidDev #iosdev #Marketing #SEO #DataScience #AI #5G #charts #MarketingDigital #Sales #Powerpoint #presentation #Infographic https://t.co/rUuDrSN2R4\n",
      "RT @stratorob: #Healthcare Boards Must Be Accountable For #Cybersecurity\n",
      "\n",
      "https://t.co/mc8KP8v573\n",
      "\n",
      "#Technology #TechForGood #Innovation #Da‚Ä¶\n",
      "RT @sonu_monika: eXpainable #artificialintalligence:#research https://t.co/iNTJh4Lhxt #MachineLearning #DataScience #Python #programming #C‚Ä¶\n",
      "RT @AMULETAnalytics: Never too late to go Bayesian! Great learning resource in R. #rstats #datascience https://t.co/aqDRAul5O7\n",
      "RT @KirkDBorne: Demystifying the use of the Parquet file format for #TimeSeries: https://t.co/rsgAn5mX1r by @SenXHQ HT @warp10io \n",
      "‚Äî‚Äî‚Äî‚Äî\n",
      "#IoT‚Ä¶\n",
      "RT @KirkDBorne: Critical Shift to Data in #Finance Industry = #DataDriven approaches that institutions are taking to meet industry challeng‚Ä¶\n",
      "RT @ingliguori: #infographic: Robotic Process Automation in a Nutshell \n",
      "https://t.co/K3wDiugOXm Via @ingliguori #RPA #Robotics #ArtificialI‚Ä¶\n",
      "RT @talibali786: Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Tens‚Ä¶\n",
      "RT @xEP_Network: Here is our full MLB Statistical Report for Player Props! All data made by our Algorithms! üî•\n",
      "\n",
      "If a player is not playing t‚Ä¶\n",
      "RT @Rbloggers: The Critical Shift to Data in the Finance Industry  {https://t.co/GpBI4GCd8K} #rstats #DataScience\n",
      "RT @KirkDBorne: Critical Shift to Data in #Finance Industry = #DataDriven approaches that institutions are taking to meet industry challeng‚Ä¶\n",
      "RT @Rbloggers: A-State R User Group Hope to Make a Comeback with Physical Events This Summer  {https://t.co/zlKtNlWh9D} #rstats #DataScience\n",
      "RT @Rbloggers: Should I say ‚Äùthere is no difference‚Äù or ‚Äùthe difference is not significant‚Äù?  {https://t.co/cr9cDbsEHR} #rstats #DataScience\n",
      "RT @foldercase_com: #FAIRdata starts in your own research group and collaborations.\n",
      "\n",
      "Utilization (and exchange) of standards, data inventor‚Ä¶\n",
      "Thanks for sharing dr @Khulood_Almani \n",
      "\n",
      "Companies need to know that too üòí\n",
      "\n",
      " #HOME #futureofwork #Tech #innovation #digitaltransformation #DataScience #BigData #Analytics #AI #Python #Flutter #Fintech #WomenInSTEM #JavaScript #web3 #Coding #100DaysofCode #bot #CyberSecurity https://t.co/6qgCVv8kes\n",
      "RT @programmerjoke9: It be like that sometimes#100Daysofcode #javascript #programming #dev #linux #java #programming #CodeNewbie #python #r‚Ä¶\n",
      "Fastai Course Chapter 1 on Linux #Classification #DataScience #Jupyter https://t.co/qfGaiGuhla\n",
      "RT @fahadjjabri: Thanks for sharing dr @Khulood_Almani \n",
      "\n",
      "Companies need to know that too üòí\n",
      "\n",
      " #HOME #futureofwork #Tech #innovation #digital‚Ä¶\n",
      "RT @fahadjjabri: Thanks for sharing dr @Khulood_Almani \n",
      "\n",
      "Companies need to know that too üòí\n",
      "\n",
      " #HOME #futureofwork #Tech #innovation #digital‚Ä¶\n",
      "RT @fahadjjabri: Thanks for sharing dr @Khulood_Almani \n",
      "\n",
      "Companies need to know that too üòí\n",
      "\n",
      " #HOME #futureofwork #Tech #innovation #digital‚Ä¶\n",
      "#r #python #data #commandline #ml #datascience #machinelearning #cleandata #clean \n",
      "https://t.co/MBolCnWBQD\n",
      "\n",
      "Cleaning Data for Effective Data Science: Doing the other 80% of the work with Python, R, and command-line tools\n",
      "RT @KirkDBorne: üåüüíØüöÄPopular #MachineLearning Algorithms Explained With #Python Code: https://t.co/xc67ZU8pYt by @TheInsaneApp\n",
      "‚Äî‚Äî‚Äî‚Äî\n",
      "#BigData‚Ä¶\n",
      "RT @SophiaM29781439: Buy Trustpilot Reviews\n",
      "https://t.co/WJmw36Uw3S\n",
      "#MachineLearning #DataScience #Python #AI #100DaysOfCode #IoT #flutter‚Ä¶\n",
      "RT @tekhackers: Free #DataEngineering Courses! \n",
      "\n",
      "#BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #TensorFl‚Ä¶\n",
      "Day 32: 60 days of Data Science and Machine Learning Series https://t.co/cZNAVk3v4c  #DataScience #MachineLearning\n",
      "HACKER TECHs helps in recovering lost social media accounts and solutions #DataScience #tech #innovation #digital\n",
      "#cloud #Al #MachineLearning #loT #Web3\n",
      "#blockchain #100DaysOfCode #TensorFlow #serverless\n",
      "#computing #reactis #startup #VPN #MONEY\n",
      "#FreeNFT #free #onlyfans #usa\n",
      "RT @GuapmanR: HACKER TECHs helps in recovering lost social media accounts and solutions #DataScience #tech #innovation #digital\n",
      "#cloud #Al‚Ä¶\n",
      "RT @GuapmanR: HACKER TECHs helps in recovering lost social media accounts and solutions #DataScience #tech #innovation #digital\n",
      "#cloud #Al‚Ä¶\n",
      "RT @programmerjoke9: It be like that sometimes#100Daysofcode #javascript #programming #dev #linux #java #programming #CodeNewbie #python #r‚Ä¶\n",
      "SEO Proposal Google Slides Presentation Template \n",
      "https://t.co/HXaEO2qLKj\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup #digitalarts #Android #ios #AndroidDev #iosdev #Marketing #SEO #DataScience #AI #5G #charts #MarketingDigital #Sales #Powerpoint #presentation #Infographic https://t.co/YJVeVqUWkW\n",
      "RT @Sprite4it: SEO Proposal Google Slides Presentation Template \n",
      "https://t.co/HXaEO2qLKj\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup #di‚Ä¶\n",
      "RT @AMULETAnalytics: Never too late to go Bayesian! Great learning resource in R. #rstats #datascience https://t.co/aqDRAul5O7\n",
      "RT @stratorob: #Healthcare Boards Must Be Accountable For #Cybersecurity\n",
      "\n",
      "https://t.co/mc8KP8v573\n",
      "\n",
      "#Technology #TechForGood #Innovation #Da‚Ä¶\n",
      "RT @Sprite4it: Best Marketing Plan PowerPoint Presentation Template \n",
      "https://t.co/vYwlIOzjqS\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup‚Ä¶\n",
      "RT @Eli_Krumova: ‚ö°Ô∏èMake Your #Twitter Feed #AI-Friendlyüê¶\n",
      "https://t.co/LPXgSN0SIP\n",
      "\n",
      "BooksüëáüèΩ\n",
      "https://t.co/CuBcbxrh47\n",
      "\n",
      "v/@KirkDBorne\n",
      "#100DaysOf‚Ä¶\n",
      "We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming #CodeNewbie\n",
      "#reactjs #bugbounty #DataScience #gamedev\n",
      "#BigData #Analytics #NeuralNetworks #Cloud\n",
      "#OpenSource #Artificial\n",
      "#linux #lpic1 #certification #book #exercises #simulations #linuxessentials #DataScience #DataVisualization #linuxtips #comptia #linuxplus #Ubuntu #Java #redhat #devops\n",
      "\n",
      "30%off on https://t.co/5fzeWmw4yQ\n",
      "\n",
      "To practice linux and pass Lpic-1 certification easily üòÄ https://t.co/itDYQYUoPs\n",
      "RT @Sprite4it: Best Marketing Plan PowerPoint Presentation Template \n",
      "https://t.co/vYwlIOzjqS\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup‚Ä¶\n",
      "RT @stratorob: #Healthcare Boards Must Be Accountable For #Cybersecurity\n",
      "\n",
      "https://t.co/mc8KP8v573\n",
      "\n",
      "#Technology #TechForGood #Innovation #Da‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @1Lpic: #linux #lpic1 #certification #book #exercises #simulations #linuxessentials #DataScience #DataVisualization #linuxtips #comptia‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "@programmerjoke9 It is most cases users faults no one reads the instructions and many make assumptions üò£üòñüò£\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "HACKER TECHs has helped a lot recover there lost account be it Snapchat and lots #ML #Al #DataScience #Analytics #BigData\n",
      "#Python #loT #lloT #loTPL #loTCL\n",
      "#DigitalTransformation #futureofwork\n",
      "#DEVCommunity #100DaysOfCode\n",
      "#CodeNewbie #WomenInSTEM #STEM #Tech\n",
      "#onlyfans #usa #Scam\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @SemaSgaier: Cool interview w/ @BDataScientist. Good pt re: how #datascience is becoming intrinsically part of many professions.\n",
      "‚ÄúWhethe‚Ä¶\n",
      "RT @tekhackers: 15 #Python Coding Interview Questions You Must Know!\n",
      "\n",
      "@kdnuggets #BigData #Analytics #DataScience #AI #MachineLearning #IoT‚Ä¶\n",
      "We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming #CodeNewbie\n",
      "#reactjs #bugbounty #DataScience #gamedev\n",
      "#BigData #Analytics #NeuralNetworks #Cloud\n",
      "#OpenSource #Artificial_Intelligence\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @zakiul33: GIT Command Cheat Sheet \n",
      "#MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "HACKER TECHs for solutions. @Kred\n",
      "#influence #STEM #EdTech #WomenInSTEM\n",
      "#WomeninTech #WomenWhoCode #AI #ML\n",
      "#loT #lloT #loTPL #DataScience #tech\n",
      "#CyberSecurity #coding #Digital\n",
      "#FutureofWork #EmergingTech #Equality\n",
      "#Inclusion #EducationForAll #job #people #world #AWE2022\n",
      "RT @modin_project: ‚ú® New major release for Modin 0.15.0! \n",
      "\n",
      "This release includes significant upgrades to Modin's core functionalities, üêº su‚Ä¶\n",
      "RT @modin_project: ‚ú® New major release for Modin 0.15.0! \n",
      "\n",
      "This release includes significant upgrades to Modin's core functionalities, üêº su‚Ä¶\n",
      "A fully-managed and highly-scalable database for vectors\n",
      "\n",
      "https://t.co/i5djUcwv1q\n",
      "\n",
      "Pretty cool, huh?\n",
      "Ya - we think so, too. #MachineLearning #DataScience\n",
      "RT @Khulood_Almani: üßë‚Äç‚öñÔ∏èHigh-tech #Legislation Through Self-regulation\n",
      "\n",
      "https://t.co/fWhOzRk3F1\n",
      "\n",
      "#Tech #law #innovation #DataScience #BigDa‚Ä¶\n",
      "We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming #CodeNewbie\n",
      "#reactjs #bugbounty #DataScience #gamedev\n",
      "#BigData #Analytics #NeuralNetworks #Cloud\n",
      "#partnerships #advertisement #AWE2022 #instagram\n",
      "RT The Cost of Making Statistical Errors https://t.co/VAur6VMNlM #datascience #error #dataanalysis #statistics #machinelearning https://t.co/CurjQDbfEW\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @JobPreference: NEED a #JOB?\n",
      "Sign up now https://t.co/o7lVlsCHXv\n",
      "FREE. NO MIDDLEMAN\n",
      "#ArtificialIntelligence #MachineLearning #Python #Da‚Ä¶\n",
      "RT @zakiul33: GIT Command Cheat Sheet \n",
      "#MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @talibali786: Best of #Linux Networking #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "Social media technical\n",
      "issues and assistances contact HACKER TECHs\n",
      "#MachineLearning #python #influence #STEM\n",
      "#DataScience #tech\n",
      "#CyberSecurity #coding #Digital\n",
      "#FutureofWork #EmergingTech #Equality\n",
      "#Inclusion #EducationForAll #DEI #computer #admin\n",
      "RT @GuapmanR: Social media technical\n",
      "issues and assistances contact HACKER TECHs\n",
      "#MachineLearning #python #influence #STEM\n",
      "#DataScience #te‚Ä¶\n",
      "@zaidsunny61 üöÄ SHIBA MOVE RUN üöÄ\n",
      "üî∞Spywolf | Pinksale | InterFi Network KYC\n",
      "üîêSpywolf Audit\n",
      "‚úÖSC:75 BNB - HC:150 BNB‚úÖ\n",
      "üïíPresale: https://t.co/2EYVhy36Qz\n",
      "\n",
      "07/06 15:00 (UTC) ~ 08/06 15:00 (UTC)\n",
      "$SMR: 0xeb48b42331F4C5D4458DD1c077E897dFFcb691b8 \n",
      "https://t.co/nJT5IINSwX\n",
      "RT @talibali786: Frontend V/S Backend #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Tens‚Ä¶\n",
      "@GuapmanR Are you interested in new subscriber üíì Send me your Pictures  for ·ë≠·ñáO·ó∞OTIO·ëé DMüåü @fanslypromort üíñ (171k)sub.\n",
      "RT @DataScienceDojo: üí°Here is a list of 42 projects in Python that you should try out!\n",
      "Source: @RavitJain\n",
      "\n",
      "#Python #Projects #DataScience h‚Ä¶\n",
      "We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming #CodeNewbie\n",
      "#reactjs #bugbounty #DataScience #gamedev\n",
      "#BigData #Analytics #NeuralNetworks #Cloud #partnerships #advertisement #usa\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @Sheraj99: A Cheat-Sheet for all the Data Structures in #Python. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #RStat‚Ä¶\n",
      "RT @PythonMaps: All roads lead to Rome. This map is visualises the famous roads built by the Roman empire. I have removed the land to highl‚Ä¶\n",
      "The Critical Shift to Data in the Finance Industry via #rbloggers #rstats #datascience https://t.co/veZQfXWHpZ\n",
      "Best Startup Business Plan PowerPoint Presentation Template \n",
      "https://t.co/Q2mxZHjUQ3\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup #digitalarts #Android #ios #AndroidDev #iosdev #Marketing #SEO #DataScience #AI #5G #charts #MarketingDigital #Keynote #organization #presentation https://t.co/KpRqEteY72\n",
      "HACKER TECHs for solutions. @Kred.\n",
      "#influence #STEM #EdTech #WomenInSTEM\n",
      "#WomeninTech #WomenWhoCode #AI #ML\n",
      "#loT #lIoT #loTPL #DataScience #tech\n",
      "#CyberSecurity #coding #Digital\n",
      "#FutureofWork #EmergingTech #Equality\n",
      "#Inclusion #EducationForAll #DEI\n",
      "#womenempowerment #SDGs\n",
      "RT @gp_pulipaka: A Great List of 60+ #Books for ML Practitioners. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #Python‚Ä¶\n",
      "RT @Tanjilasmm: #Infographic: 4 Pillars of #DataScience \n",
      "\n",
      "#BigData #Analytics #AI #IoT #IIoT #PyTorch #Python #TensorFlow #Java #JavaScript‚Ä¶\n",
      "https://t.co/O5Cuh2EZOj \n",
      "\n",
      "#machinelearning #beginner #datascience #ml #artificialintelligence #100daysofcode #ai #ds #python #datamodeling \n",
      "\n",
      "Data Science for Beginners: 4 Books in 1\n",
      "RT @AndrewinContact: Many Ways #ArtificialIntelligence Is Used\n",
      "\n",
      "Info via @CatherineAdenle simple but crucial as it shows the many #AI uses.‚Ä¶\n",
      "RT @GuapmanR: HACKER TECHs for solutions. @Kred.\n",
      "#influence #STEM #EdTech #WomenInSTEM\n",
      "#WomeninTech #WomenWhoCode #AI #ML\n",
      "#loT #lIoT #loTPL‚Ä¶\n",
      "RT @sonu_monika: AFib History is the quiet beginning of huge #Apple #health revolution. https://t.co/PrL5xEHsjv #MachineLearning #DataScien‚Ä¶\n",
      "Solutions at HACKER TECHS for hacked\n",
      "accounts and recoveries! #programmingjoke #code #coding #javascript\n",
      "#python #datascience #programming\n",
      "#programmer #joke #100daysofcode #webdev\n",
      "#webdevelopment #php #java #linux #css\n",
      "#programmingmemes #codinglife #codingpics\n",
      "#programmingjokes\n",
      "RT @GuapmanR: Solutions at HACKER TECHS for hacked\n",
      "accounts and recoveries! #programmingjoke #code #coding #javascript\n",
      "#python #datascience‚Ä¶\n",
      "Helping Next-Generation #5G Cell #Technology See Past the Trees\n",
      "by @SciTechDaily1\n",
      "\n",
      "Learn more: https://t.co/qhdkcUEIY7\n",
      "\n",
      "#AI #IoT #ArtificialIntelligence #InternetofThings #DataScience #Networking\n",
      "\n",
      "cc: @ronald_vanloon @mikequindazzi @richardsocher https://t.co/bIUp86CiVy\n",
      "RT @GuapmanR: Solutions at HACKER TECHS for hacked\n",
      "accounts and recoveries! #programmingjoke #code #coding #javascript\n",
      "#python #datascience‚Ä¶\n",
      "RT @GuapmanR: Solutions at HACKER TECHS for hacked\n",
      "accounts and recoveries! #programmingjoke #code #coding #javascript\n",
      "#python #datascience‚Ä¶\n",
      "RT @GuapmanR: Solutions at HACKER TECHS for hacked\n",
      "accounts and recoveries! #programmingjoke #code #coding #javascript\n",
      "#python #datascience‚Ä¶\n",
      "RT @sonu_monika: AFib History is the quiet beginning of huge #Apple #health revolution. https://t.co/PrL5xEHsjv #MachineLearning #DataScien‚Ä¶\n",
      "Congratulations Dr Laws! We're delighted to have you join Team PenCHORD! üéäüëèüéâFrom analysing distant stars in your #PhD to now analysing stroke treatment across the NHS! #research #DataScience #Python https://t.co/x6QnNsNTDp\n",
      "@hellovictoriav of @ArthurAI has #DataScience and #MachineLearning covered for us at the @lesbiantech #PrideSummit  #tech #lgbtqpride https://t.co/cJv40dqGix\n",
      "Artificial General Intelligence Is Not as Imminent as You Might Think - Scientific American\n",
      "\n",
      "Read more here: https://t.co/dg8xX2kwGg\n",
      "\n",
      "#ArtificialIntelligence #AI #DataScience #100DaysOfCode #Python #MachineLearning #BigData #DeepLearning #NLP #Robots #IoT\n",
      "RT @KirkDBorne: Infographic from @zakiul33 \n",
      "\n",
      "#Python Libraries and Frameworks\n",
      "‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
      "#MachineLearning #Jupyter #AI #DeepLearning #DataScien‚Ä¶\n",
      "RT @IainLJBrown: Artificial General Intelligence Is Not as Imminent as You Might Think - Scientific American\n",
      "\n",
      "Read more here: https://t.co/‚Ä¶\n",
      "Best Marketing Plan Keynote Presentation Template\n",
      "https://t.co/BH6GHJabwu\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup #digitalarts #Android #ios #AndroidDev #iosdev #Marketing #SEO #DataScience #AI #5G #charts #MarketingDigital #Keynote #organization #PowerPoint  #Template https://t.co/SWZOmbJ3KF\n",
      "RT @DataSciCampus: Join us next Wednesday for the next session of the Economic #DataScience Seminar Series with @AlexandreJudes2 from @Inde‚Ä¶\n",
      "RT @GuapmanR: Solutions at HACKER TECHS for hacked\n",
      "accounts and recoveries! #programmingjoke #code #coding #javascript\n",
      "#python #datascience‚Ä¶\n",
      "RT @chamindux: Python Debugging Cheat Sheet\n",
      "\n",
      " #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RSta‚Ä¶\n",
      "RT @_qu4nt: Infographic: Some Difference Between DS, ML, AI and DL. \n",
      "#ML #MachineLearning #BigData #Data #DataScience #DeepLearning  #AI #D‚Ä¶\n",
      "RT @gp_pulipaka: TinyML: Machine Learning at the Edge. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶\n",
      "RT @clouddatasummit: We are thrilled to announce that @PacktPub is sponsoring @clouddatasummit. Packt is an amazing resource for technical‚Ä¶\n",
      "RT @barbcarra: Thank you @ABInnovates! We‚Äôre expanding our successful #DataScience work integrated learning program to run across #AB! This‚Ä¶\n",
      "Best Real Estate PowerPoint Presentation Template\n",
      "https://t.co/bFbHW6ZYCo\n",
      "\n",
      "#DigitalMarketing #BigData #startups #startup #digitalarts #Android #ios #AndroidDev #iosdev #Marketing #SEO #DataScience #AI #5G #charts #MarketingDigital #Keynote #organization #PowerPoint #Template https://t.co/YNzttIQeUe\n",
      "You lost your account?\n",
      "A good hacker is all you need.\n",
      "Contact HACKER TECHS\n",
      "#hacked #icloud #facebookdown #imessage\n",
      "#MachineLearning #DeepLearning\n",
      "#DataScience #NLP #AI #Python\n",
      "#Cybersecurity #tech #BigData #AI #loT #bot\n",
      "#twitme #code  #Industry40\n",
      "#100DaysOfCode #iceland #Uruguay\n",
      "RT @GuapmanR: You lost your account?\n",
      "A good hacker is all you need.\n",
      "Contact HACKER TECHS\n",
      "#hacked #icloud #facebookdown #imessage\n",
      "#MachineLe‚Ä¶\n",
      "#datamodeling #datascience #dataanalysis #statistics #machinelearning #ml #r #python #ds  \n",
      " \n",
      "https://t.co/qMYjwpe3tz\n",
      "\n",
      "Practical Statistics for Data Scientists: 50+ Essential Concepts Using R and Python\n",
      "DC Police call signs that flew this month. \n",
      "#datascience #analytics #DCSkyReport https://t.co/HFwrSHbnWV\n",
      "RT @trohit007: Various Machine learning Tools, Libraries and Frameworks ‚¨áÔ∏è\n",
      "\n",
      "#MachineLearning #Jupyter #SQL #DataScience  #Cybersecurity #Bi‚Ä¶\n",
      "RT @datasciencebot_: Hi!\n",
      "\n",
      "Tweets that are encouraged - \n",
      "\n",
      "üîπQuestions related to DS\n",
      "üî∏Personal Projects\n",
      "üîπInsights into data\n",
      "üî∏Possible job oppo‚Ä¶\n",
      "RT @chamindux: Python Debugging Cheat Sheet\n",
      "\n",
      " #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RSta‚Ä¶\n",
      "RT @JobPreference: #Hiring?\n",
      "Sign up now https://t.co/o7lVlsl75X\n",
      "FREE. NO MIDDLEMEN\n",
      "#innoavtion #VR #AR #DigitalMarketing #AI #ArtificialInt‚Ä¶\n",
      "RT @GuapmanR: You lost your account?\n",
      "A good hacker is all you need.\n",
      "Contact HACKER TECHS\n",
      "#hacked #icloud #facebookdown #imessage\n",
      "#MachineLe‚Ä¶\n",
      "RT @gp_pulipaka: Top Data Science Books To Transform from Novice to Intermediate. #BigData #Analytics #DataScience #IoT #IIoT #Python #RSta‚Ä¶\n",
      "RT @zakiul33: GIT Command Cheat Sheet \n",
      "#MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @Sheraj99: A Cheat-Sheet for all the Data Structures in #Python. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #RStat‚Ä¶\n",
      "RT @InfluencerProm1: üöÄWish you a successful time.  #yourPlatformwiththeHeart #PromoEduTech #InfluencerPromotion #AI #IoT #Tech #Data #FinTe‚Ä¶\n",
      "RT @InfluencerProm1: üöÄWish you a successful time.  #yourPlatformwiththeHeart #PromoEduTech #InfluencerPromotion #AI #IoT #Tech #Data #FinTe‚Ä¶\n",
      "RT @InfluencerProm1: üöÄWish you a successful time.  #yourPlatformwiththeHeart #PromoEduTech #InfluencerPromotion #AI #IoT #Tech #Data #FinTe‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "Social media technical\n",
      "issues and assistances contact HACKER TECHs\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming #CodeNewbie\n",
      "#bugbounty #DataScience #gamedev #BigData\n",
      "#Analytics #NeuralNetworks #Cloud\n",
      "#OpenSource #DEVCommunity #codinglife\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @Sheraj99: 4 Pillars of #DataScience #MachineLearning #blockchain #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @GuapmanR: Social media technical\n",
      "issues and assistances contact HACKER TECHs\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming‚Ä¶\n",
      "iot ai via NodeXL https://t.co/GKdeZi9IKA\n",
      "@gp_pulipaka\n",
      "@ronald_vanloon\n",
      "@haroldsinnott\n",
      "@sheraj99\n",
      "@fabriziobustama\n",
      "@iotworlds\n",
      "@khulood_almani\n",
      "@chamindux\n",
      "@devretweetbot\n",
      "@fabriciosx\n",
      "\n",
      "Top hashtags:\n",
      "#ai\n",
      "#iot\n",
      "#python\n",
      "#bigdata\n",
      "#machinelearning\n",
      "#iiot\n",
      "#datascience\n",
      "#analytics /\n",
      "RT @GuapmanR: Social media technical\n",
      "issues and assistances contact HACKER TECHs\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming‚Ä¶\n",
      "RT @Sheraj99: 4 Pillars of #DataScience #MachineLearning #blockchain #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @GuapmanR: Social media technical\n",
      "issues and assistances contact HACKER TECHs\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #programming‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "Thank you for the support @ZettabytesToday ! https://t.co/kXzghx6t0b\n",
      "RT @InfluencerProm1: üöÄWish you a successful time.  #yourPlatformwiththeHeart #PromoEduTech #InfluencerPromotion #AI #IoT #Tech #Data #FinTe‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @JaeSatelliTe: Deuteronomy (instrumental)2Ô∏è‚É£ by Jae SatelliTe üõ∞ #soundcloud #lofimusic #electronicmusic #alternative #hiphop #jazz #inst‚Ä¶\n",
      "The Cost of Making Statistical Errors https://t.co/ulaKG3SDuV #datascience #error #dataanalysis https://t.co/wQjgaN44M2\n",
      "RT @JaeSatelliTe: Deuteronomy (instrumental)2Ô∏è‚É£ by Jae SatelliTeüõ∞ #soundcloud #lofimusic #electronicmusic #alternative #hiphop #jazz #instr‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @JaeSatelliTe: Deuteronomy (instrumental)2Ô∏è‚É£ by Jae SatelliTe üõ∞ #lofimusic #electronicmusic #alternative #hiphop #jazz #instrumental #mu‚Ä¶\n",
      "RT @Khulood_Almani: What are the Benefits of Using #AugmentedReality in #Ecommerce?\n",
      "\n",
      "#VR #startup #Business #Metaverse #web3 #Blockchain #N‚Ä¶\n",
      "RT @Sheraj99: 4 Pillars of #DataScience #MachineLearning #blockchain #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #Ten‚Ä¶\n",
      "RT @JaeSatelliTe: Deuteronomy (instrumental)2Ô∏è‚É£ by Jae SatelliTeüõ∞ #soundcloud #lofimusic #electronicmusic #alternative #hiphop #jazz #instr‚Ä¶\n",
      "Let me help you recover that your Hacked Facebook, Instagram, Twitter Pinterest, Gmail, Snapchat #BigData #Analytics #DataScience #loT #lloT\n",
      "#PyTorch #Python #TensorFlow #Java\n",
      "#JavaScript #ReactS #CloudComputing\n",
      "#Serverless #DataScientist #Linux\n",
      "#Programming #Coding #100DaysofCod\n",
      "RT @barbcarra: Thank you @ABInnovates! We‚Äôre expanding our successful #DataScience work integrated learning program to run across #AB! This‚Ä¶\n",
      "RT @GuapmanR: Let me help you recover that your Hacked Facebook, Instagram, Twitter Pinterest, Gmail, Snapchat #BigData #Analytics #DataSci‚Ä¶\n",
      "RT @GuapmanR: Let me help you recover that your Hacked Facebook, Instagram, Twitter Pinterest, Gmail, Snapchat #BigData #Analytics #DataSci‚Ä¶\n",
      "RT @GuapmanR: Let me help you recover that your Hacked Facebook, Instagram, Twitter Pinterest, Gmail, Snapchat #BigData #Analytics #DataSci‚Ä¶\n",
      "RT @GuapmanR: Let me help you recover that your Hacked Facebook, Instagram, Twitter Pinterest, Gmail, Snapchat #BigData #Analytics #DataSci‚Ä¶\n",
      "RT @GuapmanR: Let me help you recover that your Hacked Facebook, Instagram, Twitter Pinterest, Gmail, Snapchat #BigData #Analytics #DataSci‚Ä¶\n",
      "RT @GuapmanR: Let me help you recover that your Hacked Facebook, Instagram, Twitter Pinterest, Gmail, Snapchat #BigData #Analytics #DataSci‚Ä¶\n",
      "RT @GuapmanR: Let me help you recover that your Hacked Facebook, Instagram, Twitter Pinterest, Gmail, Snapchat #BigData #Analytics #DataSci‚Ä¶\n",
      "RT @GuapmanR: We have helped alot of people Recover their\n",
      "lost/ Hacked Account and Wallets\n",
      "#MachineLearning #python #loT\n",
      "#100DaysOfCode #pr‚Ä¶\n",
      "RT @gp_pulipaka: A Cheat-Sheet for all the Data Structures in #Python. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #RS‚Ä¶\n",
      "I retrieve all Hacked Snapchat inbox now for guide on how to recover your Account\n",
      "#hacking #snapchatdown #5G #icloud #snapchat #BigData #Analytics #DataScience #loT #lloT\n",
      "#PyTorch #Python #TensorFlow #Java\n",
      "#JavaScript #ReactS #CloudComputing\n",
      "#Serverless #DataScientist\n",
      "RT @GuapmanR: I retrieve all Hacked Snapchat inbox now for guide on how to recover your Account\n",
      "#hacking #snapchatdown #5G #icloud #snapcha‚Ä¶\n",
      "RT @GuapmanR: I retrieve all Hacked Snapchat inbox now for guide on how to recover your Account\n",
      "#hacking #snapchatdown #5G #icloud #snapcha‚Ä¶\n",
      "RT @GuapmanR: I retrieve all Hacked Snapchat inbox now for guide on how to recover your Account\n",
      "#hacking #snapchatdown #5G #icloud #snapcha‚Ä¶\n",
      "RT @GuapmanR: I retrieve all Hacked Snapchat inbox now for guide on how to recover your Account\n",
      "#hacking #snapchatdown #5G #icloud #snapcha‚Ä¶\n",
      "RT @ai_jobsNET: HIRING: Machine Learning Researcher - Saalfeld Lab / Ashburn, Virginia https://t.co/p5redkSEwa #AI #MachineLearning #DataJo‚Ä¶\n",
      "RT @KirkDBorne: Download a Free eBook on #Azure‚Å† ‚Å†#MachineLearning at https://t.co/sNuvYQ0moJ\n",
      "‚Äî‚Äî‚Äî‚Äî‚Äî\n",
      "#DeepLearning #AI #DataScience #DataMin‚Ä¶\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000019?line=0'>1</a>\u001b[0m main\u001b[39m.\u001b[39;49mfilter()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py:784\u001b[0m, in \u001b[0;36mStreamingClient.filter\u001b[0;34m(self, threaded, **params)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=781'>782</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threaded_connect(method, endpoint, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=782'>783</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect(method, endpoint, params\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py:604\u001b[0m, in \u001b[0;36mStreamingClient._connect\u001b[0;34m(self, method, endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=601'>602</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mheaders[\u001b[39m\"\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBearer \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbearer_token\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=602'>603</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://api.twitter.com/2/tweets/\u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/stream\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=603'>604</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_connect(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py:87\u001b[0m, in \u001b[0;36mBaseStream._connect\u001b[0;34m(self, method, url, auth, params, headers, body)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=83'>84</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning:\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=84'>85</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=86'>87</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39miter_lines(\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=87'>88</a>\u001b[0m     chunk_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_size\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=88'>89</a>\u001b[0m ):\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=89'>90</a>\u001b[0m     \u001b[39mif\u001b[39;00m line:\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=90'>91</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_data(line)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py:804\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=794'>795</a>\u001b[0m \u001b[39m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=795'>796</a>\u001b[0m \u001b[39mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=796'>797</a>\u001b[0m \u001b[39mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=797'>798</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=798'>799</a>\u001b[0m \u001b[39m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=799'>800</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=801'>802</a>\u001b[0m pending \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=803'>804</a>\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39mchunk_size, decode_unicode\u001b[39m=\u001b[39mdecode_unicode):\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=805'>806</a>\u001b[0m     \u001b[39mif\u001b[39;00m pending \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=806'>807</a>\u001b[0m         chunk \u001b[39m=\u001b[39m pending \u001b[39m+\u001b[39m chunk\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=757'>758</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=758'>759</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=759'>760</a>\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=760'>761</a>\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=761'>762</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py:560\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=543'>544</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=544'>545</a>\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=545'>546</a>\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=556'>557</a>\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=557'>558</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=558'>559</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=559'>560</a>\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=560'>561</a>\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=561'>562</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py:752\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=748'>749</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=750'>751</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=751'>752</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=752'>753</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=753'>754</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py:682\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=679'>680</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=680'>681</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=681'>682</a>\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline()\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=682'>683</a>\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=683'>684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=666'>667</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=667'>668</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=668'>669</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=669'>670</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=670'>671</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1236'>1237</a>\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1237'>1238</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1238'>1239</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1239'>1240</a>\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1240'>1241</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1241'>1242</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1242'>1243</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1096'>1097</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1097'>1098</a>\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1098'>1099</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1099'>1100</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1100'>1101</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main.filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def main():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000010?line=0'>1</a>\u001b[0m main()\n",
      "\u001b[1;32m/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb Cell 8'\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000009?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000009?line=3'>4</a>\u001b[0m     streaming_client\u001b[39m.\u001b[39;49mfilter()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000009?line=4'>5</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39moutput.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000009?line=5'>6</a>\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m StreamingClient\u001b[39m.\u001b[39mon_tweet():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py:784\u001b[0m, in \u001b[0;36mStreamingClient.filter\u001b[0;34m(self, threaded, **params)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=781'>782</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threaded_connect(method, endpoint, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=782'>783</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect(method, endpoint, params\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py:604\u001b[0m, in \u001b[0;36mStreamingClient._connect\u001b[0;34m(self, method, endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=601'>602</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mheaders[\u001b[39m\"\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBearer \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbearer_token\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=602'>603</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://api.twitter.com/2/tweets/\u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/stream\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=603'>604</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_connect(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py:87\u001b[0m, in \u001b[0;36mBaseStream._connect\u001b[0;34m(self, method, url, auth, params, headers, body)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=83'>84</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning:\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=84'>85</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=86'>87</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39miter_lines(\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=87'>88</a>\u001b[0m     chunk_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_size\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=88'>89</a>\u001b[0m ):\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=89'>90</a>\u001b[0m     \u001b[39mif\u001b[39;00m line:\n\u001b[1;32m     <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/tweepy/streaming.py?line=90'>91</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_data(line)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py:804\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=794'>795</a>\u001b[0m \u001b[39m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=795'>796</a>\u001b[0m \u001b[39mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=796'>797</a>\u001b[0m \u001b[39mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=797'>798</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=798'>799</a>\u001b[0m \u001b[39m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=799'>800</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=801'>802</a>\u001b[0m pending \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=803'>804</a>\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39mchunk_size, decode_unicode\u001b[39m=\u001b[39mdecode_unicode):\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=805'>806</a>\u001b[0m     \u001b[39mif\u001b[39;00m pending \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=806'>807</a>\u001b[0m         chunk \u001b[39m=\u001b[39m pending \u001b[39m+\u001b[39m chunk\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=757'>758</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=758'>759</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=759'>760</a>\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=760'>761</a>\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/requests/models.py?line=761'>762</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py:560\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=543'>544</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=544'>545</a>\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=545'>546</a>\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=556'>557</a>\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=557'>558</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=558'>559</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=559'>560</a>\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=560'>561</a>\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=561'>562</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py:752\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=748'>749</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=750'>751</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=751'>752</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=752'>753</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=753'>754</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py:682\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=679'>680</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=680'>681</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=681'>682</a>\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline()\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=682'>683</a>\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/site-packages/urllib3/response.py?line=683'>684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=666'>667</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=667'>668</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=668'>669</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=669'>670</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/socket.py?line=670'>671</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1236'>1237</a>\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1237'>1238</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1238'>1239</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1239'>1240</a>\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1240'>1241</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1241'>1242</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1242'>1243</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1096'>1097</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1097'>1098</a>\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1098'>1099</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1099'>1100</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/niclapenna/opt/anaconda3/envs/lhl_env/lib/python3.8/ssl.py?line=1100'>1101</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000005?line=3'>4</a>\u001b[0m             f\u001b[39m.\u001b[39mwrite(json\u001b[39m.\u001b[39mdumps(line))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000005?line=4'>5</a>\u001b[0m             f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000005?line=6'>7</a>\u001b[0m main()\n",
      "\u001b[1;32m/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb Cell 5'\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000005?line=1'>2</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(output_file, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000005?line=2'>3</a>\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m api\u001b[39m.\u001b[39mGetStreamFilter(track\u001b[39m=\u001b[39mFILTER, languages\u001b[39m=\u001b[39mLANGUAGES):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclapenna/Documents/GitHub/LHL_Data_Bootcamp/Week_1/Day_3/stream_tweets_v2.ipynb#ch0000005?line=3'>4</a>\u001b[0m             f\u001b[39m.\u001b[39mwrite(json\u001b[39m.\u001b[39mdumps(line))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with open(\"output.txt\", 'a') as f:\n",
    "        for line in api.GetStreamFilter(track=FILTER, languages=LANGUAGES):\n",
    "            f.write(json.dumps(line))\n",
    "            f.write('\\n')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(output_file=\"output.txt\"):\n",
    "    with open(output_file, 'a') as f:\n",
    "        for line in stream.filter(track=[\"Tweepy\"]):\n",
    "            f.write(json.dumps(line))\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eaee7f08749df7acde7defcf9c75ec9e0490b46ee4fb9b854947ce622c4fcf4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('lhl_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
